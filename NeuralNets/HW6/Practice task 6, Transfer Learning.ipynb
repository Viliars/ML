{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Семинар 6 \"Transfer Learning\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ФИО: __Иванов Иван Иванович__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предлагается поучаствовать в конкурсе https://www.kaggle.com/c/human-protein-atlas-image-classification \n",
    "\n",
    "Для зачета требуется получить значение f-меры на leaderboard не меньше 0.25 и прислать ноутбук с кодом и кратким отчетом: что пробовали, что сделали, мысли почему окончательная архитектура лучше остальных.\n",
    "\n",
    "Называйте команду или своего юзера с суффиксом [sphere].\n",
    "\n",
    "Также первые 3 человека получат бонусные 5, 3, 1 балл соответственно. (deadline: 23:59 19 ноября 2018). Скорее всего будут дополнительные плюшки для призеров конкурса.\n",
    "\n",
    "При работе на сервере используйте данные из папки /mnt/disk/exch/human-protein-atlas-image-classification . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### У kaggle есть удобное api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install kaggle # use --user when working on server\n",
    "## replace ~/.kaggle/kaggle.json with a file from your kaggle profile page\n",
    "## Download data\n",
    "!kaggle competitions download -c human-protein-atlas-image-classification\n",
    "## Sumbit \n",
    "!kaggle competitions submit -c human-protein-atlas-image-classification -f submit.csv -m \"submition description\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys, os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision.models import resnet50\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils, datasets\n",
    "from torch.nn import CrossEntropyLoss, Sequential, Linear, Sigmoid, Tanh, BCELoss, Softmax, BatchNorm1d\n",
    "from torch.utils.data.sampler import Sampler, SubsetRandomSampler, WeightedRandomSampler\n",
    "from PIL import Image # Replace by accimage when ready\n",
    "from PIL.Image import FLIP_LEFT_RIGHT, FLIP_TOP_BOTTOM, ROTATE_90, ROTATE_180, ROTATE_270\n",
    "from PIL.ImageEnhance import Color, Contrast, Brightness, Sharpness\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csv_ = pd.read_csv(\"data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00070df0-bbc3-11e8-b2bc-ac1f6b6435d0</td>\n",
       "      <td>16 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000a6c98-bb9b-11e8-b2b9-ac1f6b6435d0</td>\n",
       "      <td>7 1 2 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000a9596-bbc4-11e8-b2bc-ac1f6b6435d0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000c99ba-bba4-11e8-b2b9-ac1f6b6435d0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001838f8-bbca-11e8-b2bc-ac1f6b6435d0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Id   Target\n",
       "0  00070df0-bbc3-11e8-b2bc-ac1f6b6435d0     16 0\n",
       "1  000a6c98-bb9b-11e8-b2b9-ac1f6b6435d0  7 1 2 0\n",
       "2  000a9596-bbc4-11e8-b2bc-ac1f6b6435d0        5\n",
       "3  000c99ba-bba4-11e8-b2b9-ac1f6b6435d0        1\n",
       "4  001838f8-bbca-11e8-b2bc-ac1f6b6435d0       18"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SubsetSampler(Sampler):\n",
    "     \"\"\"Samples elements from a given list of indices.\n",
    " \n",
    "     Arguments:\n",
    "         indices (list): a list of indices\n",
    "     \"\"\"\n",
    " \n",
    "     def __init__(self, indices):\n",
    "        self.num_samples = len(indices)\n",
    "        self.indices = indices\n",
    " \n",
    "     def __iter__(self):\n",
    "        return iter(self.indices)\n",
    " \n",
    "     def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "\n",
    "class MultilabelDataset(Dataset):\n",
    "    \"\"\"Dataset wrapping images and target labels for Kaggle\n",
    "\n",
    "    Arguments:\n",
    "        A CSV file path\n",
    "        Path to image folder\n",
    "        Extension of images\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, csv_path, img_path, img_ext, transform=None, train=True):\n",
    "    \n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        assert self.df['Id'].apply(lambda x: os.path.isfile(img_path + x + img_ext)).all(), \\\n",
    "\"Some images referenced in the CSV file were not found\"\n",
    "        \n",
    "        self.mlb = MultiLabelBinarizer()\n",
    "        self.img_path = img_path\n",
    "        self.img_ext = img_ext\n",
    "        self.transform = transform\n",
    "\n",
    "        self.X = self.df['Id']\n",
    "        if train:\n",
    "            self.y = self.mlb.fit_transform(self.df['Target'].str.split()).astype(np.float32)\n",
    "        else:\n",
    "            self.y = self.df['Target']\n",
    "\n",
    "    def X(self):\n",
    "        return self.X\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(self.img_path + self.X[index] + self.img_ext)\n",
    "        img = img.convert('RGB')\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        label = self.y[index]\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df.index)\n",
    "    \n",
    "    def getLabelEncoder(self):\n",
    "        return self.mlb\n",
    "    \n",
    "    def getDF(self):\n",
    "        return self.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = MultilabelDataset('data/train.csv','data/train/','_green.png',\n",
    "                                 data_transforms['train']\n",
    "                                 )\n",
    "X_val = MultilabelDataset('data/train.csv','data/train/','_green.png',\n",
    "                                 data_transforms['val']\n",
    "                                 )\n",
    "X_val.mlb = X_train.mlb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_idx, valid_idx = train_test_split(np.array(range(len(X_train))), test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetSampler(valid_idx)\n",
    "batch_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(X_train,\n",
    "                          batch_size=batch_size,\n",
    "                          sampler=train_sampler,\n",
    "                          num_workers=4)\n",
    "\n",
    "valid_loader = DataLoader(X_val,\n",
    "                      batch_size=batch_size,\n",
    "                      sampler=valid_sampler,\n",
    "                      num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pretrained_model = resnet50(pretrained=True)\n",
    "for param in pretrained_model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_ftrs = pretrained_model.fc.in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Замените ``pretrained_model.fc`` на новую полносвязную сеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pretrained_model.fc = Sequential( ## Your code here )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_cuda = False\n",
    "if use_cuda:\n",
    "    pretrained_model = pretrained_model.cuda(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtype=torch.FloatTensor\n",
    "\n",
    "def train(network, epochs, learning_rate, train_dataloader, test_dataloader, loss=BCELoss(), optim=torch.optim.Adam):\n",
    "    train_loss_epochs = []\n",
    "    test_loss_epochs = []\n",
    "    optimizer = optim(network.parameters(), lr=learning_rate)\n",
    "    try:\n",
    "        for epoch in range(epochs):\n",
    "            losses = []\n",
    "            for X, y in train_dataloader:\n",
    "                if use_cuda:\n",
    "                    X = Variable(X).cuda(3)\n",
    "                    y = Variable(y).cuda(3)\n",
    "                else:\n",
    "                    X = Variable(X)\n",
    "                    y = Variable(y)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                prediction = network(X)\n",
    "                loss_batch = loss(prediction, y)\n",
    "                losses.append(loss_batch.data[0].cpu())\n",
    "\n",
    "                loss_batch.backward()\n",
    "                optimizer.step()\n",
    "  \n",
    "            train_loss_epochs.append(np.mean(losses))\n",
    "            losses = []    \n",
    "            for X, y in test_dataloader:\n",
    "                if use_cuda:\n",
    "                    X = Variable(X).cuda(3)\n",
    "                    y = Variable(y).cuda(3)\n",
    "                else:\n",
    "                    X = Variable(X)\n",
    "                    y = Variable(y)\n",
    "                \n",
    "                prediction = network(X)\n",
    "                loss_batch = loss(prediction, y)\n",
    "                losses.append(loss_batch.data[0].cpu())\n",
    "                \n",
    "            test_loss_epochs.append(np.mean(losses))\n",
    "            sys.stdout.write('\\rEpoch {0}... (Train/Test) BCE: {1:.3f}/{2:.3f}'.format(\n",
    "                        epoch, train_loss_epochs[-1], test_loss_epochs[-1]))\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.plot(train_loss_epochs[1:], label='Train')\n",
    "    plt.plot(test_loss_epochs[1:], label='Test')\n",
    "    plt.xlabel('Epochs', fontsize=16)\n",
    "    plt.ylabel('Loss', fontsize=16)\n",
    "    plt.legend(loc=0, fontsize=16)\n",
    "    plt.grid('on')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(pretrained_model, ?, ?, train_loader, valid_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions_validation = []\n",
    "targets = []\n",
    "for X, y in valid_loader:\n",
    "    if use_cuda:\n",
    "        X = Variable(X).cuda(3)\n",
    "    else:\n",
    "        X = Variable(X)\n",
    "   \n",
    "    prediction = pretrained_model(X)\n",
    "    predictions_validation.append(prediction.data.cpu().numpy())\n",
    "    targets.append(y.cpu().numpy())\n",
    "\n",
    "predictions_validation = np.concatenate(preds)\n",
    "targets = np.concatenate(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#find optimal threshold for probabilities\n",
    "threshold = ?\n",
    "print (f1_score(targets, (predictions_validation > threshold).astype(int), average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csv_sub = pd.read_csv(\"data/sample_submission.csv\")\n",
    "csv_sub.columns = [\"Id\", \"Target\"]\n",
    "csv_sub.to_csv(\"data/sample_submission_for_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = MultilabelDataset('data/sample_submission_for_dataset.csv','data/test/','_green.png',\n",
    "                                  data_transforms['val'], train=False\n",
    "                                 )\n",
    "X_test.mlb = X_train.mlb\n",
    "test_loader = DataLoader(X_test,\n",
    "                          batch_size=batch_size,\n",
    "                          num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for X, _ in test_loader:\n",
    "    if use_cuda:\n",
    "        X = Variable(X).cuda(3)\n",
    "    else:\n",
    "        X = Variable(X)\n",
    "    \n",
    "    prediction = pretrained_model(X)\n",
    "    predictions.append(prediction.data.cpu().numpy())\n",
    "\n",
    "predictions_test = np.concatenate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csv_sub = pd.read_csv(\"data/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csv_sub[\"Predicted\"] = list(map(lambda t: \" \".join([str(x) for x in t]), [list(map(int, t)) for t in X_train.mlb.inverse_transform((predictions_test > threshold))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csv_sub.to_csv(\"submit.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
